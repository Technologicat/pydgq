# -*- coding: utf-8 -*-
"""Support routines for Galerkin integrators.

This loads in the data generated by pydgq.utils.precalc, and provides some auxiliary routines
for dealing with Galerkin representations.
"""

from __future__ import division, print_function, absolute_import

import cPickle as pickle

import numpy as np

from pylu import dgesv   # Cython-based LU decomposition and linear equation system solver, callable from inside nogil blocks -- Python interface (using np.arrays)
from pylu cimport dgesv as dgesv_c  # -"- -- Cython interface (using raw pointers, explicit sizes)

from . cimport types
from . cimport compsum

##################
# C-level helpers
##################

# Assemble Galerkin series at given points inside the timestep.
#
# The points are specified implicitly, by evaluating the basis functions at the desired points (see the parameter psi, below).
#
# Space DOFs are independent, each has its own Galerkin series. This assembles them all in one go.
#
# u:     rank-2 array, size [n_space_dofs,  n_time_dofs]: Galerkin coefficients; u[j,i] is the coefficient of psi[i] for component u_j(x)
# psi:   rank-2 array, size [n_time_dofs, n_points]:      basis functions evaluated at each of the points x[i] (at which the series is to be assembled); psi[j,i] is psi[j]( x[i] )
# uass:  rank-2 array, size [n_points, n_space_dofs]:     output, values of u; uass[j,i] is u_i( x[j] )
# ucorr: rank-1 array, size [n_points]:                   correction storage for compensated summation
#
#                                       coeffs      basis         output
cdef void assemble( types.DTYPE_t* u, types.DTYPE_t* psi, types.DTYPE_t* uass, types.DTYPE_t* ucorr, int n_space_dofs, int n_time_dofs, int n_points ) nogil:
    cdef unsigned int i,j,k

#    # naive summation
#    for k in range(n_space_dofs):
#
#        # zero out the assembled values for this space DOF
#        for i in range(n_points):
#            uass[ i*n_space_dofs + k ] = 0.0
#
#        # sum contributions from each basis function
#        for j in range(n_time_dofs):
#            for i in range(n_points):
#                uass[ i*n_space_dofs + k ] += u[ k*n_time_dofs + j ] * psi[ j*n_points + i ]

    # compensated summation
    cdef types.DTYPE_t* ps
    cdef types.DTYPE_t* pc
    for k in range(n_space_dofs):

        # Zero out the assembled values for this space DOF.
        #
        # Also zero out the correction array. Note that since we process one space DOF at a time, we only need one correction array.
        # The same position uass[i,k] gets written multiple times during the inner loops, but each time k changes, a new summation begins
        # (at that point, the sums for any previous k are not updated any more).
        #
        for i in range(n_points):
            uass[ i*n_space_dofs + k ] = 0.0
            ucorr[ i ] = 0.0

        # Sum contributions from each basis function.
        for i in range(n_points):
            # Compute the pointers only once for each i.
            ps = &uass[ i*n_space_dofs + k ]  # sum (accumulator)
            pc = &ucorr[ i ]                  # correction
            for j in range(n_time_dofs):
                compsum.accumulate( ps, pc, u[ k*n_time_dofs + j ] * psi[ j*n_points + i ] )


# Assemble Galerkin series at the end of the timestep.
#
# Compared to the general-purpose assemble():
#   - Only N[1] (the linear basis function associated with the endpoint) is nonzero at the endpoint. Its value there is exactly 1.
#   - There are always at least 2 basis functions (the linear ones).
#   - For this purpose, n_points is always 1.
#
cdef void final_value( types.DTYPE_t* u, types.DTYPE_t* uass, int n_space_dofs, int n_time_dofs ) nogil:
    cdef unsigned int k
    for k in range(n_space_dofs):
        # here only one visualization point, so uass[ n_space_dofs*0 + k ] --> uass[ k ]
        uass[ k ] = u[ k*n_time_dofs + 1 ]


# Integrate over the timestep by applying a quadrature.
#
# funcvals: array of function values at the quadrature points (rank-1 or C order)
# qw:       array of quadrature weights (rank-1 or C order), length must match that of funcvals
# n:        number of items in funcvals and qw
# dt:       size of timestep (will be used for scaling the result)
#
cdef types.DTYPE_t do_quadrature( types.DTYPE_t* funcvals, types.DTYPE_t* qw, int n, types.DTYPE_t dt ) nogil:
    cdef unsigned int i

#    # naive summation (not good for problems sensitive to initial conditions, such as vibration problems with low damping)
#    cdef types.DTYPE_t s
#    s = 0.0
#    for i in range(n):
#        s += qw[i]*funcvals[i]

    # compensated summation
    cdef types.DTYPE_t s, c
    s = qw[0]*funcvals[0]  # first term in sum; no correction by Kahan algorithm (if we wanted to correct, we should take the roundoff from this multiplication, instead)
    c = 0.0
    for i in range(1,n):
        compsum.accumulate( &s, &c, qw[i]*funcvals[i] )

    # Scale the result to account for the length of the timestep.
    #
    # This amounts to a change of variable in the integral, as is commonly used in finite element methods.
    # ( For a refresher, see https://en.wikipedia.org/wiki/Integration_by_substitution#Substitution_for_single_variable )
    #
    # We use a simple affine scaling so that the Jacobian is constant across the timestep.
    # The reference interval is [-1,1], so its length is 2; the target length is dt; thus we must scale by dt/2.
    #
    # More formally, the affine mapping of xi: [-1,1] --> x: [a,b] is
    #
    #    x = a + (b - a) ( xi - (-1) ) / ( 1 - (-1) )
    #      = a + (b - a) ( xi + 1 ) / 2
    #      = a + (1/2) (b - a) ( xi + 1 )
    #
    # Hence by differentiation,
    #
    #    dx/dxi = (b - a) / 2
    #
    # and in our application, (b - a) = dt.
    #
    s *= dt/2.0

    return s


#########################
# Integration algorithms
#########################

# Time-discontinuous Galerkin.
#
cdef int dG( params* gp ) nogil:

#    # array shapes and types in gp:
#
#    # instance arrays (see galerkin.Helper.allocate_storage())
#    cdef types.DTYPE_t[:,:,::1] g     = np.empty( [n_space_dofs,n_time_dofs,n_quad], dtype=DTYPE, order="C" )  # effective load vector, for each space DOF, for each time DOF, at each integration point
#    cdef types.DTYPE_t[:,::1]   b     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # right-hand sides (integral, over the timestep, of g*psi)
#    cdef types.DTYPE_t[:,::1]   u     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients (unknowns)
#    cdef types.DTYPE_t[:,::1]   uprev = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients from previous iteration
#    cdef types.DTYPE_t[:,::1]   uass  = np.empty( [n_quad,n_space_dofs],             dtype=DTYPE, order="C" )  # u, assembled for integration (this ordering needed for speed!)
#    cdef types.DTYPE_t[::1]     ucorr = np.empty( [n_quad],                          dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for integration)
#    cdef types.DTYPE_t[:,::1]   uvis  = np.empty( [nx,n_space_dofs],                 dtype=DTYPE, order="C" )  # u, assembled for visualization
#    cdef types.DTYPE_t[::1]     ucvis = np.empty( [nx],                              dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for visualization)
#
#    # global arrays, same for each solver instance (see galerkin.Helper.load_data(), galerkin.Helper.prep_solver())
#    cdef types.DTYPE_t[:,::1] LU      = galerkin.helper_instance.LU       # LU decomposed mass matrix (packed format), for one space DOF, shape (n_time_dofs, n_time_dofs)
#    cdef int[::1]       p       = galerkin.helper_instance.p        # row permutation information, length n_time_dofs
#    cdef int[::1]       mincols = galerkin.helper_instance.mincols  # band information for L, length n_time_dofs
#    cdef int[::1]       maxcols = galerkin.helper_instance.maxcols  # band information for U, length n_time_dofs
#    cdef types.DTYPE_t[::1]   qw      = galerkin.helper_instance.integ_w  # quadrature weights (Gauss-Legendre)
#    cdef types.DTYPE_t[:,::1] psi     = galerkin.helper_instance.integ_y  # basis function values at the quadrature points, psi[j,i] is N[j]( x[i] )
#    cdef types.DTYPE_t[:,::1] psivis  = galerkin.helper_instance.vis_y    # basis function values at the visualization points, psivis[j,i] is N[j]( x[i] )

    cdef types.DTYPE_t[gp.n_space_dofs] up  # temporary storage for u'
    cdef unsigned int nequals  # for convergence check

    cdef DTYPE_t tcurr  # t at current quadrature point

    # Loop counters.
    #
    # j = space DOF
    # k = time DOF
    # l = quadrature point
    # m = implicit iteration (Banach fixed point iteration)
    #
    cdef unsigned int j, k, l, m

    # Initialize the Galerkin coefficients u: initially, we set u = u0, which has been saved as the array w.
    #
    for j in range(gp.n_space_dofs):
        gp.u[j*n_time_dofs + 0]     = gp.w[j]  # value at start of timestep
        gp.u[j*n_time_dofs + 1]     = gp.w[j]  # value at end of timestep

        # value of Galerkin coefficients at previous iteration, for convergence check
        gp.uprev[j*n_time_dofs + 0] = gp.w[j]
        gp.uprev[j*n_time_dofs + 1] = gp.w[j]

        # bubbles
        for k in range(2,gp.n_time_dofs):
            gp.u[j*n_time_dofs + k]     = 0.0
            gp.uprev[j*n_time_dofs + k] = 0.0

    # Implicit iteration (Banach/Picard fixed point iteration)
    #
    for m in range(gp.maxit):

        # Assemble u at the quadrature points for this iteration.
        #
        # This forms the core of the Banach fixed point iteration: here we use the
        # previous Galerkin coefficients u (latest known iterate) to model the behavior of u
        # inside the timestep.
        #
        # The old coefficients are then no longer needed; they get overwritten by the solver below.
        #
        assemble( gp.u, gp.psi, gp.uass, gp.ucorr, gp.n_space_dofs, gp.n_time_dofs, gp.n_quad )

        # Form the right-hand side at each quadrature point.
        #
        for l in range(gp.n_quad):
            tcurr = gp.t + gp.dt*gp.tquad[l]

            # Get the instantaneous value of u' at this quadrature point.
            #
            f(&gp.uass[gp.n_space_dofs*l + 0], up, gp.n_space_dofs, tcurr, gp.data)

            # At the quadrature point l, compute the value of the RHS integrand
            # in the weak form (original RHS multiplied by test function).
            #
            # We do this for each space DOF independently.
            #
            # The time DOFs here correspond to the set of test functions.
            #
            for j in range(gp.n_space_dofs):
                for k in range(gp.n_time_dofs):
                    # g: [n_space_dofs,n_time_dofs,n_quad]
                    # psi: [n_time_dofs, n_quad]
                    gp.g[j*(gp.n_time_dofs*gp.n_quad) + k*gp.n_quad + l] = up[j] * gp.psi[k*gp.n_quad + l]

        # Solve the dG linear equation system (separately for each space DOF).
        #
        for j in range(gp.n_space_dofs):

            # For this space DOF, integrate the right-hand side across the timestep (for each test function).
            #
            # We use the Gauss-Legendre rule that was set up by init(). (This information is implicit
            # in the array qw, and in the array psi, which was above used to evaluate the integrand.)
            #
            for k in range(gp.n_time_dofs):
                # b: [n_space_dofs,n_time_dofs]
                # g: [n_space_dofs,n_time_dofs,n_quad]
                gp.b[j*gp.n_time_dofs + k] = do_quadrature( &gp.g[j*(gp.n_time_dofs*gp.n_quad) + k*gp.n_quad + 0], gp.qw, gp.n_quad, gp.dt )

            # Add the RHS contribution from the jump term. This accounts for the initial condition for this timestep.
            #
            gp.b[j*gp.n_time_dofs + 0] += gp.w[j]

            # Solve the dG linear equation system for this space DOF.
            #
            # This updates the Galerkin coefficients u.
            #
            dgesv_c.solve_decomposed_banded_c( gp.LU, gp.p, gp.mincols, gp.maxcols, &gp.b[j*gp.n_time_dofs + 0], &gp.u[j*gp.n_time_dofs + 0], gp.n_time_dofs )

        # Check convergence; break early if converged to within machine precision.
        #
        nequals = 0
        for j in range(gp.n_space_dofs):
            for k in range(gp.n_time_dofs):
                if gp.u[j*gp.n_time_dofs + k] == gp.uprev[j*gp.n_time_dofs + k]:
                    nequals += 1
        if nequals == gp.n_space_dofs*gp.n_time_dofs:
            break

        # Store the current values for performing the convergence check at the next iteration.
        #
        for j in range(gp.n_space_dofs):
            for k in range(gp.n_time_dofs):
                gp.uprev[j*gp.n_time_dofs + k] = u[j*gp.n_time_dofs + k]

    # Store the value at the end of the this timestep (needed for the jump term at the next timestep).
    #
    final_value( gp.u, gp.uvis, gp.n_space_dofs, gp.n_time_dofs )
    for j in range(gp.n_space_dofs):
        gp.w[j] = gp.uvis[0*gp.n_space_dofs + j]  # first row of uvis = first visualization point

    return (m+1)


# Continuous Galerkin.
#
# This is almost the same code as dG, the only difference being in the handling of the load vector.
#
cdef int cG( params* gp ) nogil:

#    # array shapes and types in gp:
#
#    # instance arrays (see galerkin.Helper.allocate_storage())
#    cdef types.DTYPE_t[:,:,::1] g     = np.empty( [n_space_dofs,n_time_dofs,n_quad], dtype=DTYPE, order="C" )  # effective load vector, for each space DOF, for each time DOF, at each integration point
#    cdef types.DTYPE_t[:,::1]   b     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # right-hand sides (integral, over the timestep, of g*psi)
#    cdef types.DTYPE_t[:,::1]   u     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients (unknowns)
#    cdef types.DTYPE_t[:,::1]   uprev = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients from previous iteration
#    cdef types.DTYPE_t[:,::1]   uass  = np.empty( [n_quad,n_space_dofs],             dtype=DTYPE, order="C" )  # u, assembled for integration (this ordering needed for speed!)
#    cdef types.DTYPE_t[::1]     ucorr = np.empty( [n_quad],                          dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for integration)
#    cdef types.DTYPE_t[:,::1]   uvis  = np.empty( [nx,n_space_dofs],                 dtype=DTYPE, order="C" )  # u, assembled for visualization
#    cdef types.DTYPE_t[::1]     ucvis = np.empty( [nx],                              dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for visualization)
#
#    # global arrays, same for each solver instance (see galerkin.Helper.load_data(), galerkin.Helper.prep_solver())
#    cdef types.DTYPE_t[:,::1] LU      = galerkin.helper_instance.LU       # LU decomposed mass matrix (packed format), for one space DOF, shape (n_time_dofs, n_time_dofs)
#    cdef int[::1]       p       = galerkin.helper_instance.p        # row permutation information, length n_time_dofs
#    cdef int[::1]       mincols = galerkin.helper_instance.mincols  # band information for L, length n_time_dofs
#    cdef int[::1]       maxcols = galerkin.helper_instance.maxcols  # band information for U, length n_time_dofs
#    cdef types.DTYPE_t[::1]   qw      = galerkin.helper_instance.integ_w  # quadrature weights (Gauss-Legendre)
#    cdef types.DTYPE_t[:,::1] psi     = galerkin.helper_instance.integ_y  # basis function values at the quadrature points, qy[j,i] is N[j]( x[i] )
#    cdef types.DTYPE_t[:,::1] psivis  = galerkin.helper_instance.vis_y    # basis function values at the visualization points, qy[j,i] is N[j]( x[i] )

    cdef types.DTYPE_t[gp.n_space_dofs] up  # temporary storage for u'
    cdef unsigned int nequals  # for convergence check

    cdef DTYPE_t tcurr  # t at current quadrature point

    # Loop counters.
    #
    # j = space DOF
    # k = time DOF
    # l = quadrature point
    # m = implicit iteration (Banach fixed point iteration)
    #
    cdef unsigned int j, k, l, m

    # Initialize the Galerkin coefficients u: initially, we set u = u0, which has been saved as the array w.
    #
    for j in range(gp.n_space_dofs):
        gp.u[j*gp.n_time_dofs + 0]     = gp.w[j]  # value at start of timestep
        gp.u[j*gp.n_time_dofs + 1]     = gp.w[j]  # value at end of timestep

        # value of Galerkin coefficients at previous iteration, for convergence check
        gp.uprev[j*gp.n_time_dofs + 0] = gp.w[j]
        gp.uprev[j*gp.n_time_dofs + 1] = gp.w[j]

        # bubbles
        for k in range(2,gp.n_time_dofs):
            gp.u[j*gp.n_time_dofs + k]     = 0.0
            gp.uprev[j*gp.n_time_dofs + k] = 0.0

    # Implicit iteration (Banach/Picard fixed point iteration)
    #
    for m in range(gp.maxit):

        # Assemble latest known u at the quadrature points for this iteration.
        #
        assemble( gp.u, gp.psi, gp.uass, gp.ucorr, gp.n_space_dofs, gp.n_time_dofs, gp.n_quad )

        # Form the right-hand side at each quadrature point.
        #
        for l in range(gp.n_quad):
            tcurr = gp.t + gp.dt*gp.tquad[l]

            # Get the instantaneous value of u' at this quadrature point.
            #
            f(&gp.uass[gp.n_space_dofs*l + 0], up, gp.n_space_dofs, tcurr, gp.data)

            # Compute the value of the RHS integrand in the weak form.
            for j in range(gp.n_space_dofs):
                for k in range(gp.n_time_dofs):
                    # g: [n_space_dofs,n_time_dofs,n_quad]
                    # psi: [n_time_dofs, n_quad]
                    gp.g[j*(gp.n_time_dofs*gp.n_quad) + k*gp.n_quad + l] = up[j] * gp.psi[k*gp.n_quad + l]

        # Solve the cG linear equation system (separately for each space DOF).
        #
        for j in range(gp.n_space_dofs):

            # For this space DOF, integrate the right-hand side across the timestep (for each test function).
            #
            for k in range(1,gp.n_time_dofs):  # note that the load vector for time DOF 0 will be filled in separately (initial condition)
                # b: [n_space_dofs,n_time_dofs]
                # g: [n_space_dofs,n_time_dofs,n_quad]
                gp.b[j*gp.n_time_dofs + k] = do_quadrature( &gp.g[j*(gp.n_time_dofs*gp.n_quad) + k*gp.n_quad + 0], gp.qw, gp.n_quad, gp.dt )

            # Account for the initial condition in the load vector.
            #
            # The first time basis function (index 0) is the only one that is nonzero at the start point of the timestep;
            # its value there is exactly 1. Hence the value of the first time DOF (index 0) for space DOF j can be set to w[j].
            #
            # The mass matrix on the LHS has already been adjusted in init() to have the multiplicative identity on the first row,
            # so that when the linear equation system is solved, u[j,0] will just pick up the value set here.
            #
            gp.b[j*gp.n_time_dofs + 0] = gp.w[j]

            # Solve the cG linear equation system for this space DOF.
            #
            # This updates the Galerkin coefficients u.
            #
            dgesv_c.solve_decomposed_banded_c( gp.LU, gp.p, gp.mincols, gp.maxcols, &gp.b[j*gp.n_time_dofs + 0], &gp.u[j*gp.n_time_dofs + 0], gp.n_time_dofs )

        # Check convergence; break early if converged to within machine precision.
        #
        nequals = 0
        for j in range(gp.n_space_dofs):
            for k in range(gp.n_time_dofs):
                if gp.u[j*gp.n_time_dofs + k] == gp.uprev[j*gp.n_time_dofs + k]:
                    nequals += 1
        if nequals == gp.n_space_dofs*gp.n_time_dofs:
            break

        # Store the current values for performing the convergence check at the next iteration.
        #
        for j in range(gp.n_space_dofs):
            for k in range(gp.n_time_dofs):
                gp.uprev[j*gp.n_time_dofs + k] = gp.u[j*gp.n_time_dofs + k]

    # Store the value at the end of the this timestep (needed for the initial condition at the next timestep).
    #
    final_value( gp.u, gp.uvis, gp.n_space_dofs, gp.n_time_dofs )
    for j in range(gp.n_space_dofs):
        gp.w[j] = gp.uvis[0*gp.n_space_dofs + j]  # first row of uvis = first visualization point

    return (m+1)


#######################
# Python-level helpers
#######################

# When instantiated, the following object performs the common initialization that is needed only once per process,
# including the construction of the mass matrix for the first-order initial value problem
# for a single space DOF:
#
#   u'    = f( u(t), t ),   t in (-1,1)
#   u(-1) = u0
#
# This is done in generic form over the reference element [-1,1]. The LU decomposition
# of the matrix is also formed. The LU decomposition can then be used for fast solving
# of the linear equation systems in the main solver loop.
#
#
# Thread-safety:
#   Multiple dG (or cG) solvers may be running at the same time, but they *must* have the same settings (method and q).
#   Simultaneous processing with different settings is currently not supported and will cause errors and/or crashes. (TODO)
#
#
# Multiple "space" degrees of freedom in the semilinear ODE system
#
#   M u' = g( u(t), t )                         (*)
#
# are to be handled by the user-provided kernel by formally inverting M:
#
#   u' = M^(-1) g( u(t), t ) =: f( u(t), t )    (**)
#
# The problem (**) (first and last form) is of the standard form handled by the solver.
#
# From the last two forms of (**), we have (multiplying from the left by M)
#
#   M f = g
#
# Thus, the kernel can solve a linear equation system (different from the dG(q) one!) to
# obtain the effective load f whenever it is needed. See kernels.pyx for examples.
#
# This needs M, g and the latest u (all "space" degrees of freedom), and outputs the
# corresponding value of f (for all "space" degrees of freedom).
#
# This in turn allows us to solve the time evolution of each "space" degree of freedom separately,
# for each of them using the time integrator that handles a single "space" degree of freedom.
#
# (In addition to "space" degrees of freedom, i.e. degrees of freedom in the ODE system,
#  there are also "time" degrees of freedom, of which there are q+1 for *each* "space" degree of freedom.
#  These "time" degrees of freedom are the ones whose behavior is encoded in the Galerkin mass matrix C, below.
#
#  We use the label "space" degrees of freedom, because ODE systems like (*) typically arise
#  in space discretization of PDE problems.)
#
#
class Helper:
    """Helper class to manage the Galerkin solver."""

    def __init__(self, q, method, nx, rule=None):
        """Perform global initialization of the Galerkin solver.

        This object must be instantiated before using the integrators "dG" or "cG".
        See the module-level global function init(), which does this.

        During one session (run of the process), one initialization is enough for all simulations
        using the same method (combination of "q" and "method"). To change the settings, simply initialize again.

        The Galerkin solver uses the hierarchical basis functions (linears, plus bubbles
        based on integrated Legendre polynomials).

        Parameters:
            q : int, >= 1
                Polynomial degree of basis. In practice, 1 or 2 are usually good values.

                The upper limit available depends on data stored in the precalculated data file (pydgq_data.bin).
                To determine what your data file has, instantiate a Helper and call its load_data() method.

            method : string
                Which Galerkin method to use:

                 "dG" : time-discontinuous Galerkin (recommended)
                    The solution is finitely discontinuous (C^{-1}) across timestep boundaries,
                    with left-continuity at each boundary.

                    Because no degrees of freedom are wasted on enforcing continuity,
                    this allows better approximation at the same q.

                 "cG" : continuous Galerkin
                    Conforming finite elements in time.

                    The solution is C0-continuous across timestep boundaries. This may be
                    more intuitive for visualization, but note that usually the approximation
                    is much worse than with dG.

            nx : int
                Number of visualization points per computed timestep.

                This corresponds to the parameter "interp" of odesolve.result_len(),
                odesolve.make_tt() and odesolve.ivp().

                !!! Currently, the value of interp in all subsequent calls to odesolve.ivp() must be the same
                    as the value of nx passed here. This is a implementation-technical limitation
                    that may be removed in the future. !!!

            rule : int or None
                Order of the Gauss-Legendre quadrature to use for integrating the load vector.
                If None (default), the highest available order is used (see pydqg.utils.precalc).

                To determine what your data file has, instantiate a Helper and call its load_data() method.
        """

        if q < 1:
            raise ValueError( "q must be >= 1; got %d" % (q) )
        if nx < 1:
            raise ValueError( "nx must be >= 1; got %d" % (nx) )
        if method not in ["dG", "cG"]:
            raise ValueError( "Unknown method '%s'; valid: 'dG', 'cG'" % (method) )

        self.method      = method
        self.q           = q
        self.n_time_dofs = q+1  # the hierarchical basis of degree q has q+1 degrees of freedom.
        self.nx          = nx   # number of visualization points per timestep

        plural_s = "s" if self.nx > 1 else ""
        print( "Galerkin integrator support initializing for %s(%d) with %d visualization point%s per timestep..." % (method, q, nx, plural_s) )

        try:
            self.load_data(rule)
            self.build_C()
            self.prep_solver()
            self.storage = {}
            self.available = True
            print( "    Initialization successful." )
        except Exception as e:
            # precomputed data for Gauss-Legendre integration (used for processing the load vector in the solver)
            self.integ_x     = None   # GL points
            self.integ_y     = None   # values of basis functions at GL points
            self.integ_w     = None   # GL weights
            self.rule        = None   # order of the chosen GL rule (integer)

            # precomputed data for timestep visualization
            self.vis_x       = None   # visualization points
            self.vis_y       = None   # values of basis functions at visualization points
            self.nx          = None   # number of visualization points within each timestep

            self.q           = None   # degree of basis
            self.n_time_dofs = None   # number of "time degrees of freedom" for each "space degree of freedom"

            self.C           = None   # Galerkin mass matrix
            self.LU          = None   # the LU decomposition of C
            self.p           = None   # row permutation for load vector ( L U = P C,  so if  C u = b,  then  P C u = P b  and thus  L U u = P b )
            self.mincols     = None   # band information for L
            self.maxcols     = None   # band information for U

            self.storage     = None   # storage for solver instance arrays

            self.available   = False  # Galerkin integrators enabled/disabled

            print( "    Initialization failed. Galerkin integrators disabled." )
            raise

    # Load precalculated data for the hierarchical basis functions.
    #
    def load_data(self, rule):
        """Load precalculated data (pydgq_data.bin).

        The hierarchical basis functions are numerically sensitive to cancellation especially at high degrees q,
        hence must be computed using higher internal precision (double is not enough).

        Because arbitrary precision floating point in pure software is slow, pydqg.utils.precalc makes
        a precomputed array for this routine to load.

        Parameters:
            rule = order of integration rule, or None for default
        """
        q           = self.q
        n_time_dofs = self.n_time_dofs
        nx          = self.nx

        # TODO: use pkg_resources to find installed data file

        filename = 'pydgq_data.bin'
        try:
            with open(filename, 'rb') as infile:
                data = pickle.load( infile )
        except IOError as e:
            print( "    Cannot find data file '%s'. The file can be generated by running the module pydqg.utils.precalc as the main program." % filename )
            raise

        maxq    = data["maxq"]
        maxnx   = data["vis"]["maxnx"]
        maxrule = data["integ"]["maxrule"]
        print( "    Loaded precomputed Galerkin data with maxq = %d, maxnx = %d, maxrule = %d" % (maxq, maxnx, maxrule) )

        # Sanity check that we have enough data available
        #
        if q > maxq:
            raise ValueError("Data file '%s' contains data up to degree maxq=%d, but the requested degree was higher, q=%d. Use a lower q or re-run pydqg.utils.precalc for higher maxq." % (filename, maxq, q))
        needx = nx+1 if self.method == "cG" else nx  # "visualization" points are used for evaluating the result inside the timestep (see parameter "interp" of odesolve.result_len(), odesolve.make_tt() and odesolve.ivp()).
        if needx > maxnx:
            raise ValueError("Data file '%s' contains data up to visualization maxnx=%d, but the needed number of points is higher, %d. Use a lower nx or re-run pydqg.utils.precalc for higher maxnx." % (filename, maxnx, needx))
        if rule is not None and rule > maxrule:
            raise ValueError("Data file '%s' contains data for integration rules up to order %d, but the requested order was higher, rule=%d. Use a lower rule." % (filename, maxrule, rule))

        # Choose the order of the Gauss-Legendre quadrature and the number of visualization points.
        #
        # The load is not a polynomial, so we default to the highest available integration rule.
        #
        # The Gauss-Legendre rule of order q (where q us the degree of the basis) would be enough for our mass matrix C;
        # the fact that the matrix has the integrand N'*N and not N*N saves us one order, compared to the usual q+1.
        #
        # But we handle the matrix analytically, so the required order needed by the matrix does not matter;
        # Gauss-Legendre is used only for processing the load vector.
        #
        # If we wanted to be exact, we should least-squares fit the load to the given basis before performing the quadrature; this would give us computable error.
        # However, doing that is expensive, since the quadrature runs inside the loop for implicit iterations (iterative linearization using the Banach fixed point theorem).
        #
        if rule is None:
            default_str = " (default)"
            rule = maxrule
        else:
            default_str = ""
        self.rule = rule  # save it for information

        print( "        Selected Gauss-Legendre rule of order %d%s" % (rule, default_str) )

        # Choose the appropriate data arrays
        #
        integ = data["integ"][rule]

        if self.method == "dG":
            # In dG, the value of the solution at the end of the timestep is different
            # from its value at the beginning of the next timestep, even though these points
            # occur at the same value of t.
            #
            # (Technically speaking, the solution is left-continuous, i.e. the end-of-timestep
            #  point has the actual value of the solution at that value of t.
            #
            #  The start-of-next-timestep point represents the limit from the right.)
            #
            # Thus, we just take the subdivision that has nx points (including both endpoints).
            #
            vis = data["vis"][nx]

        else: # self.method == "cG":
            # In cG, the endpoint of timestep n is the start point of timestep n+1.
            # Avoid visualizing it twice.
            #
            # To get the desired number of points, take one more, and then discard the start point,
            # obtaining nx unique points.
            #
            vis = data["vis"][nx+1]
            vis["x"] = vis["x"][1:]
            vis["y"] = vis["y"][:,1:]

        # Chop off higher degree basis functions from the y arrays, if the arrays contain more data than what we actually need.
        #
        if data["maxq"] > q:
            integ["y"] = integ["y"][ :(q+1), : ]
            vis["y"]   = vis["y"][   :(q+1), : ]
            print( "        Unloaded extraneous data for polynomial degrees > q=%d" % q )

        # Explicitly set C ordering and the correct datatype.
        #
        # This eliminates strided indexing in the generated C code. See
        #     http://uni-graz.at/~haasegu/Lectures/GPU_CUDA/Lit/seljebotn_cython.pdf
        #     http://docs.scipy.org/doc/numpy/reference/arrays.nditer.html
        #
        # This is usually used like:
        #   cdef types.DTYPE_t[:,::1] ww = np.empty( [nt, n_space_dofs], dtype=DTYPE, order="C" )
        #
        # Note:
        #   - types.DTYPE_t in the cdef vs. DTYPE in the Python call to np.empty()
        #   - C storage order
        #
        cdef types.DTYPE_t[::1]   integ_x = np.empty( [ rule ],              dtype=DTYPE, order="C" )
        cdef types.DTYPE_t[::1]   integ_w = np.empty( [ rule ],              dtype=DTYPE, order="C" )
        cdef types.DTYPE_t[:,::1] integ_y = np.empty( [ n_time_dofs, rule ], dtype=DTYPE, order="C" )
        cdef types.DTYPE_t[::1]   vis_x   = np.empty( [ nx ],                dtype=DTYPE, order="C" )
        cdef types.DTYPE_t[:,::1] vis_y   = np.empty( [ n_time_dofs, nx ],   dtype=DTYPE, order="C" )

        integ_x[:]   = integ["x"][:]
        integ_y[:,:] = integ["y"][:,:]
        integ_w[:]   = integ["w"][:]
        vis_x[:]     = vis["x"][:]
        vis_y[:,:]   = vis["y"][:,:]

        self.integ_x = integ_x
        self.integ_y = integ_y
        self.integ_w = integ_w
        self.vis_x   = vis_x
        self.vis_y   = vis_y

        # We extracted what we need, unload the rest.
        #
        del data

        # Now the loaded data can be accessed as follows:
        #
        # Gauss-Legendre integration (will be used for processing the load vector):
        #  - self.integ_x: Gauss-Legendre points of the chosen rule, in (-1,1)
        #  - self.integ_w: corresponding Gauss-Legendre weights
        #  - self.integ_y: values of basis functions at the Gauss-Legendre points; y[j,i] is N[j]( x[i] )
        #  - self.rule:    order of the chosen Gauss-Legendre rule (for information only)
        #
        # Visualization:
        #  - self.vis_x:   x values for visualization (actually, time value in [-1,1])
        #  - self.vis_y:   values of basis functions at the visualization points; y[j,i] is N[j]( x[i] )

    def build_C(self):
        """Build the dG(q) mass matrix C.

        C contains integrals of Ni'*Nj (i column, j row) over the reference element [-1,1],
        where the Ns are the hierarchical (Lobatto) basis functions.

        This routine uses an analytical result (see the user manual), avoiding the need
        to numerically evaluate the integrands to get this. This approach is both
        much more accurate and much faster.
        """
        # Note that there is no need to scale C by the length of each timestep, because the one differentiation and the integration exactly cancel out the Jacobians.

        q = self.q
        n = q+1

        C = np.zeros( (n,n), dtype=np.float64 )
        C[0,0] = -1./2.
        C[0,1] =  1./2.
        C[1,0] = -1./2.
        C[1,1] =  1./2.

        if q >= 2:
            t = 1./np.sqrt(6.)
            C[0,2] = -t
            C[1,2] =  t
            C[2,0] =  t
            C[2,1] = -t

        # General formula for C_ji for j,i >= 2.
        for j in range(2,n):
            i = j + 1  # i-1 = j  <=>  i = j+1
            if i >= 2 and i < n:
                C[j,i] =  2. * np.sqrt( 1. / ( ( 2.*j - 1. ) * ( 2.*j + 1. ) ) )
            i = j - 1  # i+1 = j  <=>  i = j-1
            if i >= 2 and i < n:
                C[j,i] = -2. * np.sqrt( 1. / ( ( 2.*j - 1. ) * ( 2.*j - 3. ) ) )

        if self.method == "dG":
            # Jump term for discontinous Galerkin (dG). N[0] is the only basis function that is nonzero at x=-1.
            #
            # See the user manual for derivation.
            #
            C[0,0] += 1.0
        else: # self.method == "cG":
            # In continuous Galerkin (cG), we don't have the jump term; there we must instead:
            #
            #   - Eliminate the first degree of freedom by substituting in its known value (eliminating a row and column, transferring the known terms to the load), or
            #   - Replace the first row with the multiplicative identity and replace the first component of the load with the known value of the first degree of freedom.
            #
            # The first is more elegant (disturbing the matrix structure less), while the second is easier to code. Both approaches achieve the same result.
            # Note that both require implementation also in the timestepping code that fills in the load vector (not just in this helper class).
            #
            # We use the easier second approach, because then we won't need to remap DOF numbers. Also, the  problem is antisymmetric (skew-symmetric),
            # i.e. a symmetric solver could not be used in any case. Note also that the equation system will be rather small, and the hierarchical
            # basis functions are good for numerical linear algebra (far from linear dependence in the sense of the L2 inner product), so there
            # should not be much roundoff or cancellation.
            #
            C[0,:] = 0.0
            C[0,0] = 1.0

        print( "    Mass matrix" )
        print( "        Constructed %dx%d for %s(%d)" % (n,n, self.method,q) )

        self.C = C

    def prep_solver(self):
        """Prepare the dG(q) linear equation system for solving."""
        LU,p = dgesv.lup_packed(self.C)
        self.LU = LU
        self.p  = p
        print( "        LU decomposition with partial pivoting done" )

        mincols,maxcols = dgesv.find_bands(LU, tol=1e-15)
        self.mincols = mincols
        self.maxcols = maxcols
        r   = np.arange(self.q+1, dtype=int)
        bwL = np.max(r - mincols)  # convention: diagonal matrix = zero bandwidth ( https://en.wikipedia.org/wiki/Band_matrix )
        bwU = np.max(maxcols - r)
        print( "        Banded solver detected bandwidths L=%d (lower bw), U=%d (upper bw)" % (bwL, bwU) )

    def allocate_storage(self, solver_id, n_space_dofs):
        """Allocate per-problem storage.

        This must be called separately for each problem that will be running simultaneously (even if same settings),
        as each problem instance needs its own work space.

        Parameters:
            solver_id : hashable
                unique identifier (use id() of some local variable that is unique across instances, e.g. the result array ww)
            n_space_dofs : int
                number of space DOFs (i.e. size of the 1st-order ODE system) that the current problem has.
        """

        assert self.storage is not None
        assert self.n_time_dofs is not None
        assert self.rule is not None
        assert self.nx is not None

        n_time_dofs = self.n_time_dofs
        n_quad      = self.rule  # Gauss-Legendre has as many quadrature points as the order of the rule being used.
        nx          = self.nx

        cdef types.DTYPE_t[:,:,::1] g     = np.empty( [n_space_dofs,n_time_dofs,n_quad], dtype=DTYPE, order="C" )  # effective load vector, for each space DOF, for each time DOF, at each integration point
        cdef types.DTYPE_t[:,::1]   b     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # right-hand sides (integral, over the timestep, of g*psi)
        cdef types.DTYPE_t[:,::1]   u     = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients (unknowns)
        cdef types.DTYPE_t[:,::1]   uprev = np.empty( [n_space_dofs,n_time_dofs],        dtype=DTYPE, order="C" )  # Galerkin coefficients from previous iteration
        cdef types.DTYPE_t[:,::1]   uass  = np.empty( [n_quad,n_space_dofs],             dtype=DTYPE, order="C" )  # u, assembled for integration (this ordering needed for speed!)
        cdef types.DTYPE_t[::1]     ucorr = np.empty( [n_quad],                          dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for integration)
        cdef types.DTYPE_t[:,::1]   uvis  = np.empty( [nx,n_space_dofs],                 dtype=DTYPE, order="C" )  # u, assembled for visualization
        cdef types.DTYPE_t[::1]     ucvis = np.empty( [nx],                              dtype=DTYPE, order="C" )  # correction for compensated summation in assemble() (for visualization)

        items = {}

        items["n_space_dofs"] = n_space_dofs

        items["g"]     = g
        items["b"]     = b
        items["u"]     = u
        items["uprev"] = uprev
        items["uass"]  = uass
        items["ucorr"] = ucorr
        items["uvis"]  = uvis
        items["ucvis"] = ucvis

        self.storage[solver_id] = items
        return items

    def free_storage(self, solver_id):
        """Deallocate per-problem storage."""
        self.storage.pop(solver_id, None)   # http://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-dictionary


helper_instance = None
def init(q=3, method="dG", nx=1, rule=None):
    """Initialize Galerkin solver.

    This function must be called before using the integrators "dG" or "cG".

    During one session (run of the process), one initialization is enough for all simulations
    using the same method (combination of "q" and "method"). To change the settings, simply initialize again.

    The Galerkin solver uses the hierarchical (Lobatto) basis functions (linears, plus bubbles
    based on integrated Legendre polynomials).

    Parameters (see Helper.__init__ for full description):
        q : int, >= 1
            Polynomial degree of basis.

        method : str
            Which Galerkin method to use.

        nx : int, >= 1
            Number of visualization points per computed timestep.

             !!! Currently, the value of interp in all subsequent calls to odesolve.ivp() must be the same
                 as the value of nx passed here. This is a implementation-technical limitation
                 that may be removed in the future. !!!

        rule : int or None
            Order of the Gauss-Legendre quadrature to use for integrating the load vector.
            None = highest available.
    """
    # TODO: relax the technical limitation on nx <-> interp
    global helper_instance
    helper_instance = Helper(q, method, nx, rule)

